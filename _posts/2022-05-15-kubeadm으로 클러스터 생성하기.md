---
layout: single
title: kubeadmìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ìƒì„±í•˜ê¸° With NCP
categories: Kubernetes
tag: [Kubernetes, DevOps, NCP]
toc: true
author_profile: false
sidebar:
    nav: "docs"
---
# 1. ì‚¬ì „ì¤€ë¹„

## 1) ë°©í™”ë²½ í¬íŠ¸ ì—´ê¸°_<small>Master Node/Worker Node</small>


> **ğŸ’¡ Default ACG** 
> - ëª¨ë“  ë“¤ì–´ì˜¤ëŠ” ì—°ê²°(inbound) ì°¨ë‹¨  
> - ëª¨ë“  ë‚˜ê°€ëŠ” ì—°ê²°(outbound) í—ˆìš©  
> - ì›ê²© ì ‘ì† ê¸°ë³¸ í¬íŠ¸ (Linux - 22, Windows - 3389)ì— ëŒ€í•œ TCP í—ˆìš© _(Default ACG)_


- **ê³µí†µ**
    - TCP 22ë²ˆ
- **Master Node**
    
    
    | TCP | Inbound | 6443 | Kubernetes API server | All |
    | --- | --- | --- | --- | --- |
    | TCP | Inbound | 2379-2380 | etcd server client API | kube-apiserver, etcd |
    | TCP | Inbound | 10250 | kubelet API | Self, Control Plane |
    | TCP | Inbound | 10259 | kube-scheduler | Self |
    | TCP | Inbound | 10257 | kube-controller-manager | Self |
- **Worker Node**
    
    
    | TCP | Inbound | 10250 | kubelet API | Self, Control Plane |
    | --- | --- | --- | --- | --- |
    | TCP | Inbound | 30000-32767 | NodePort Services | All |

### (1) NCPì—ì„œ ì„œë²„ ìƒì„±


1. **ì„œë²„ ìƒì„±**
	- Services > Compute > Server > ì„œë²„ ìƒì„±
    - <small>ë„¤íŠ¸ì›Œí¬ë¥¼ ìƒì„¸í•˜ê²Œ ì‹ ê²½ ì“°ì§€ ì•Šê³  ë¦¬ì „ ê°„ì˜ ì‚¬ì„¤ í†µì‹ ë§Œ í•˜ê¸° ìœ„í•´ VPC ë³´ë‹¤ **Classic**ìœ¼ë¡œ ì„ íƒ!</small>  
2. **ì„œë²„ ì´ë¯¸ì§€ ì„ íƒ**
	- ë¶€íŒ… ë””ìŠ¤í¬ í¬ê¸° : `50GB` > ì´ë¯¸ì§€íƒ€ì… : `OS` > OS ì´ë¯¸ì§€íƒ€ì… : `Ubuntu` > ì„œë²„ íƒ€ì… : `Standard` > ì„œë²„ ì´ë¯¸ì§€ : `ubuntu-18.04` ì„ íƒ > ë‹¤ìŒ
	- <small>Kubernetes ê³µì‹ ë¬¸ì„œì—ì„œ <u>ì„œë²„ ìƒì„± ì¡°ê±´</u> í™•ì¸</small>  
3. **ì„œë²„ ì„¤ì •**
	- Zone ì„ íƒ : `KR-2` > ìŠ¤í† ë¦¬ì§€ ì¢…ë¥˜ : `SSD` > ì„œë²„ ì„¸ëŒ€ : `g1` > ì„œë²„ íƒ€ì… : `Standard` / `vCPU 2ê°œ, ë©”ëª¨ë¦¬ 4GB, [SSD]ë””ìŠ¤í¬ 50GB [g1]` > ìš”ê¸ˆì œ ì„ íƒ : `ì›”ìš”ê¸ˆì œ` > ì„œë²„ ê°œìˆ˜ : `1` > ì„œë²„ ì´ë¦„ : `master-node` > ë°˜ë‚© ë³´í˜¸ : `í•´ì œ` > ë‹¤ìŒ    

4. **ì¸ì¦í‚¤ ì„¤ì •**
	- `ìƒˆë¡œìš´ ì¸ì¦í‚¤ ìƒì„±` > ì¸ì¦í‚¤ ì´ë¦„ : `master-node-key` > `ì¸ì¦í‚¤ ìƒì„± ë° ì €ì¥` í´ë¦­ > ë‹¤ìŒ  

5. **ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ ì„¤ì •**
	- `ì‹ ê·œ ACG ìƒì„±` > `+ACG ìƒì„±` > ACG ì´ë¦„ : `master-node-acg` > ì„¤ì •í•  ACG ê°’ ì…ë ¥ > ìƒì„±  
    - ê°ê°ì˜ í•„ìš”í•œ ACG ì„¤ì • ê°’ + ì›ê²© ì ‘ì†ì„ ìœ„í•œ 22ë²ˆ í¬íŠ¸ í—ˆìš©  

6. **ìµœì¢… í™•ì¸**
    

### (2) ì„œë²„ ì ‘ì† í™˜ê²½ ì„¤ì •

- **í¬íŠ¸ í¬ì›Œë”© ì„¤ì •**
    - í¬íŠ¸ í¬ì›Œë”© ì„¤ì • > ì™¸ë¶€ í¬íŠ¸ì˜ ê°’ì€ 1024~65534 ë²”ìœ„ ë‚´ë¡œ ì…ë ¥ > `+ì¶”ê°€` > ì ìš©
- **ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ í™•ì¸í•˜ê¸°**
    - ì„œë²„ ê´€ë¦¬ ë° ì„¤ì • ë³€ê²½ > `ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ í™•ì¸` > ì¸ì¦í‚¤ íŒŒì¼ ì²¨ë¶€ > `ë¹„ë°€ë²ˆí˜¸ í™•ì¸` í´ë¦­ > ì„œë²„ ì´ë¦„, ê´€ë¦¬ì ì´ë¦„, ë¹„ë°€ë²ˆí˜¸ í™•ì¸ <small>*(í•´ë‹¹ ë¹„ë°€ë²ˆí˜¸ëŠ” ì„œë²„ ì ‘ì† ì‹œ í•„ìš”í•œ ì •ë³´ì´ë¯€ë¡œ ë³µì‚¬í•˜ì—¬ ë³„ë„ë¡œ ì €ì¥ í•„ìš”)*</small> > í™•ì¸

### (3) ì„œë²„ ì ‘ì†

1. ì„œë²„ ì ‘ì†ìš© ê³µì¸ IP, ì™¸ë¶€ í¬íŠ¸ í™•ì¸  
2. Putty ì„¤ì¹˜ ë° ì‹¤í–‰  
3. ì„œë²„ ì ‘ì†ìš© ê³µì¸ IP, ì™¸ë¶€ í¬íŠ¸ ì…ë ¥  
4. login as: `root` / password : ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ë‹¨ê³„ì—ì„œ í™•ì¸ëœ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥  
5. `passwd root`ë¡œ ë¹„ë°€ë²ˆí˜¸ ë³€ê²½  

## 2) ëŸ°íƒ€ì„ Docker ì„¤ì¹˜_<small>Master Node/Worker Node</small>

>ğŸ’¡ **To install Docker Engine**, you need the 64-bit version of one of these Ubuntu versions:
>- Ubuntu Impish 21.10
>- Ubuntu Hirsute 21.04
>- Ubuntu Focal 20.04 (LTS)
>- Ubuntu Bionic 18.04 (LTS)
>- ~~Ubuntu Linux 16.04 (LTS) ì§€ì› ì¤‘ë‹¨~~

### (1) Set up the repository

1. `apt` packageÂ ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜
    
    ```jsx
    root@master-node1:~# sudo apt-get update
    	Hit:1 http://kr.archive.ubuntu.com/ubuntu bionic InRelease
    	Hit:2 http://kr.archive.ubuntu.com/ubuntu bionic-updates InRelease
    	Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease
    	Hit:4 http://kr.archive.ubuntu.com/ubuntu bionic-backports InRelease
    	Reading package lists... Done
    root@master-node1:~# apt-get install \
    >     ca-certificates \
    >     curl \
    >     gnupg \
    >     lsb-release
    ```
    
    
2. Dockerì˜ ê³µì‹ GPG í‚¤ ì¶”ê°€
    
    ```jsx
    root@master-node1:~#  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
    ```
    
    
3. **stable**Â repository ì„¤ì • <small>_(repository ì„¤ì¹˜ ì„¤ì • : stable/nightly/test)_</small>
    
    ```jsx
    root@master-node1:~# echo \
    >   "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
    >   $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    ```
    

### (2) Install Docker Engine

- `apt`packageÂ ì—…ë°ì´íŠ¸ í›„,Â *ìµœì‹  ë²„ì „*ì˜ Docker Engine, containerd, Docker Composeë¥¼ ì„¤ì¹˜í•˜ê±°ë‚˜ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™í•˜ì—¬ íŠ¹ì • ë²„ì „ì„ ì„¤ì¹˜
    
    ```jsx
    root@master-node1:~# sudo apt-get update
    	Get:1 https://download.docker.com/linux/ubuntu bionic InRelease [64.4 kB]
    	Get:2 https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages [24.                                                                                                             3 kB]
    	Hit:3 http://kr.archive.ubuntu.com/ubuntu bionic InRelease
    	Hit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease
    	Hit:5 http://kr.archive.ubuntu.com/ubuntu bionic-updates InRelease
    	Hit:6 http://kr.archive.ubuntu.com/ubuntu bionic-backports InRelease
    	Fetched 88.8 kB in 1s (79.5 kB/s)
    	Reading package lists... Done
    root@master-node1:~# sudo apt-get install docker-ce docker-ce-cli containerd.io
    ```
    
    
    - *íŠ¹ì • ë²„ì „*ì˜ Docker Engineì„ ì„¤ì¹˜í•˜ë ¤ë©´ repositoryì— ì‚¬ìš© ê°€ëŠ¥í•œ ë²„ì „ì„ ë‚˜ì—´í•œ ë‹¤ìŒ ë‹¤ìŒì„ ì„ íƒí•˜ì—¬ ì„¤ì¹˜
        
        ```jsx
        root@master-node1:~# apt-cache madison docker-ce
        	 docker-ce | 5:20.10.14~3-0~ubuntu-bionic | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages
        	 docker-ce | 5:19.03.15~3-0~ubuntu-bionic | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages
        	 docker-ce | 5:18.09.9~3-0~ubuntu-bionic | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages
        	 docker-ce | 18.06.3~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages
        root@master-node1:~# sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io docker-compose-plugin
        ```
                

### (3) Configuring the container runtime cgroup driver

- container runtimeì—ì„œëŠ” kubeadmì´ kubeletì„ systemd ì„œë¹„ìŠ¤ë¡œ ê´€ë¦¬í•˜ê¸° ë•Œë¬¸ì— cgroupfs ë“œë¼ì´ë²„ ëŒ€ì‹  systemd ë“œë¼ì´ë²„ê°€ kubeadm ê¸°ë°˜ ì„¤ì •ì— ê¶Œì¥ëœë‹¤
- daemon.json íŒŒì¼ ìƒì„±í•˜ì§€ ì•Šìœ¼ë©´ `kubeadm init` ì‹¤í–‰ ì‹œ kubelet ë™ì‘ ì˜¤ë¥˜ ë°œìƒ
- ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ê³¼ kubelet cgroup ë“œë¼ì´ë²„ë¥¼ ì¼ì¹˜ì‹œì¼œì•¼ í•˜ë©° ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ kubelet í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨

```jsx
root@master-node1:~# cat > /etc/docker/daemon.json <<EOF
	> {
	>   "exec-opts": ["native.cgroupdriver=systemd"],
	>   "log-driver": "json-file",
	>   "log-opts": {
	>     "max-size": "100m"
	>   },
	>   "storage-driver": "overlay2"
	> }
	> EOF
root@master-node1:~# mkdir -p /etc/systemd/system/docker.service.d
root@master-node1:~# systemctl daemon-reload
root@master-node1:~# systemctl restart docker
```

### (4) ì„¤ì¹˜ í™•ì¸

1. `hello-world`Â ì´ë¯¸ì§€ë¥¼ ì‹¤í–‰í•˜ì—¬ Docker ì—”ì§„ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
    
    ```jsx
    root@master-node1:~# sudo docker run hello-world
    	Unable to find image 'hello-world:latest' locally
    	latest: Pulling from library/hello-world
    	2db29710123e: Pull complete
    	Digest: sha256:10d7d58d5ebd2a652f4d93fdd86da8f265f5318c6a73cc5b6a9798ff6d2b2e67
    	Status: Downloaded newer image for hello-world:latest
    	
    	Hello from Docker!
    	This message shows that your installation appears to be working correctly.
    	
    	To generate this message, Docker took the following steps:
    	 1. The Docker client contacted the Docker daemon.
    	 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    	    (amd64)
    	 3. The Docker daemon created a new container from that image which runs the
    	    executable that produces the output you are currently reading.
    	 4. The Docker daemon streamed that output to the Docker client, which sent it
    	    to your terminal.
    	
    	To try something more ambitious, you can run an Ubuntu container with:
    	 $ docker run -it ubuntu bash
    	
    	Share images, automate workflows, and more with a free Docker ID:
    	 https://hub.docker.com/
    	
    	For more examples and ideas, visit:
    	 https://docs.docker.com/get-started/
    ```
    
    
2. `docker Info` í™•ì¸
        

### [ì°¸ê³ 1] Uninstall Docker Engine

1. Docker Engine, CLI, Containerd ë° Docker Compose íŒ¨í‚¤ì§€ ì œê±°
    
    ```jsx
    sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-compose-plugin
    ```
    
2. í˜¸ìŠ¤íŠ¸ì˜ ì´ë¯¸ì§€, ì»¨í…Œì´ë„ˆ, ë³¼ë¥¨ ë˜ëŠ” ì‚¬ìš©ì ì§€ì • êµ¬ì„± íŒŒì¼ì€ ìë™ìœ¼ë¡œ ì œê±°ë˜ì§€ ì•ŠëŠ”ë‹¤.  

	ëª¨ë“  ì´ë¯¸ì§€, ì»¨í…Œì´ë„ˆ ë° ë³¼ë¥¨ì„ ì‚­ì œí•˜ë ¤ë©´:
    
    ```jsx
    sudo rm -rf /var/lib/docker
    sudo rm -rf /var/lb/containerd
    ```
    

### [ì°¸ê³ 2] Configure Docker to start on boot

- Debian/Ubuntuì—ì„œ ë¶€íŒ… ì‹œ Docker ìë™ ì‹œì‘
- ë‹¤ë¥¸ ë°°í¬íŒì—ì„œ ë¶€íŒ… ì‹œ Docker ë° Containerdë¥¼ ìë™ìœ¼ë¡œ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ ì‚¬ìš©

```jsx
root@master-node1:~# sudo systemctl enable docker.service
	Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
	Executing: /lib/systemd/systemd-sysv-install enable docker
root@master-node1:~# sudo systemctl enable containerd.service
```

## 3) kubeadm, kubelet ë° kubectl ì„¤ì¹˜_<small>Master Node/Worker Node</small>

> __ğŸ’¡ 3ê°€ì§€ toolì˜ ì‚¬ìš©ì²˜__
> - kubeadmì€ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ê³ , ì—…ë°ì´íŠ¸í•  ë•Œ ì‚¬ìš©
> - kubeletì€ ì‘ì—…ì´ ìƒê²¼ì„ ë•Œ ì‹¤ì œë¡œ ë¨¸ì‹ ì—ì„œ ì‘ì—…ì„ ì§„í–‰í•˜ëŠ” ë¨¸ì‹ ë§ˆë‹¤ í•˜ë‚˜ì”© ìˆëŠ” ì‘ì—… ê´€ë¦¬ì ì—­í• 
> - kubectlì€ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì— ëª…ë ¹ì„ ë‚´ë¦¬ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” CLI

### (1) version í˜¸í™˜_*ìˆ˜ì • ì˜ˆì •*

1. ì§€ì›ë˜ëŠ” ë²„ì „
    
    - ì¿ ë²„ë„¤í‹°ìŠ¤ ë²„ì „ì€Â **x.y.z**ë¡œ í‘œí˜„ë˜ëŠ”ë°, ì—¬ê¸°ì„œÂ **x**ëŠ” ë©”ì´ì € ë²„ì „,Â **y**ëŠ” ë§ˆì´ë„ˆ ë²„ì „,Â **z**ëŠ” íŒ¨ì¹˜ ë²„ì „
    - ì¿ ë²„ë„¤í‹°ìŠ¤ í”„ë¡œì íŠ¸ëŠ” ìµœê·¼ ì„¸ ê°œì˜ ë§ˆì´ë„ˆ ë¦´ë¦¬ìŠ¤ (1.23, 1.22, 1.21) ì— ëŒ€í•œ ë¦´ë¦¬ìŠ¤ ë¶„ê¸°ë¥¼ ìœ ì§€
    - ì¿ ë²„ë„¤í‹°ìŠ¤ 1.19 ì´ìƒì€ ì•½ 1ë…„ê°„ì˜ íŒ¨ì¹˜ ì§€ì›ì„ ë°›ëŠ”ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ 1.18 ì´ìƒì€ ì•½ 9ê°œì›”ì˜ íŒ¨ì¹˜ ì§€ì›ì„ ë°›ëŠ”ë‹¤.
2. ìµœì‹ Â kube-apiserverÂ 1.23
    - `kubelet`ì€Â `kube-apiserver`ë³´ë‹¤ ìµœì‹ ì¼ ìˆ˜ ì—†ìœ¼ë©°, 2ë‹¨ê³„ì˜ ë‚®ì€ ë§ˆì´ë„ˆ ë²„ì „ê¹Œì§€ ì§€ì›í•œë‹¤. (1.22/1.21)
    - `kube-controller-manager`,Â `kube-scheduler` ê·¸ë¦¬ê³ Â `cloud-controller-manager`ëŠ”Â **1.23**ê³¼Â **1.22**ì„ ì§€ì›. ë§ˆì´ë„ˆ ë²„ì „ê³¼ ì¼ì¹˜í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒí•˜ì§€ë§Œ, ìµœì‹  ë²„ì „ì´ë©´ ì•ˆ ë˜ê³  ìµœëŒ€ í•œ ë‹¨ê³„ ë‚®ì€ ë§ˆì´ë„ˆ ë²„ì „ê¹Œì§€ëŠ” í—ˆìš©
3. `kubectl`ì€Â `kube-apiserver`ì˜ í•œ ë‹¨ê³„ ë§ˆì´ë„ˆ ë²„ì „(ì´ì „ ë˜ëŠ” ìµœì‹ ) ë‚´ì—ì„œ ì§€ì›í•œë‹¤. 1.24/1.23/1.22
- kubeadmì€ kubeadmê³¼ ë™ì¼í•œ ë²„ì „ ë˜ëŠ” ì´ì „ ë²„ì „ì¸ Kubernetes êµ¬ì„± ìš”ì†Œì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ì •ë¦¬í•˜ìë©´
    
    ì—…ê·¸ë ˆì´ë“œ ì¤‘ì¸ ë…¸ë“œëŠ” ë…¸ë“œ ê´€ë¦¬ì— ì‚¬ìš©ëœ kubeadm ë²„ì „ê³¼ ë™ì¼í•œ MINOR ë²„ì „ ë˜ëŠ” í•˜ë‚˜ì˜ MINOR ë²„ì „ì¸ kubeadm ë²„ì „ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    
    - kubeadm ë²„ì „ 1.22ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì—…ê·¸ë ˆì´ë“œí–ˆìŠµë‹ˆë‹¤.
    - ë…¸ë“œ ì—…ê·¸ë ˆì´ë“œì— ì‚¬ìš©ë˜ëŠ” kubeadm ë²„ì „ì€ 1.22 ë˜ëŠ” 1.23ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    - ê·¸ë˜ì„œ `kubeadm` 1.23 ë²„ì „ìœ¼ë¡œ ê°€ì •í•´ì„œ ë³´ë©´
        1. `kube-apiserver`Â 1.23 **ê°™ê±°ë‚˜**
            - `kubelet`(1.23/1.22/~~1.21~~) â‡’ `kubeadm`ì´ 1.23ì´ë©´ kubeletì€ (1.23/1.22) **ê°™ê±°ë‚˜ í•œë‹¨ê³„ ë‚®ê±°ë‚˜**
            - `kube-controller-manager`,Â `kube-scheduler` ê·¸ë¦¬ê³ Â `cloud-controller-manager` (1.23/1.22)
            - `kubectl`Â (1.24/1.23/1.22)
            - `kube-proxy` (1.23/1.22) â‡’ `kube-proxy`ëŠ” ë°˜ë“œì‹œÂ `kubelet`ê³¼ ë™ì¼í•œ ë§ˆì´ë„ˆ ë²„ì „ì´ì–´ì•¼ í•œë‹¤.
        2. `~~kube-apiserver`Â 1.22 **í•œë‹¨ê³„ ë‚®ê±°ë‚˜**~~
            - `~~kubelet`(1.22/1.21) â‡’ `kubeadm`ì´ 1.23ì´ë©´ kubeletì€ (1.22) **í•œë‹¨ê³„ê¹Œì§€ í—ˆìš©**~~
            - `~~kube-controller-manager`,Â `kube-scheduler` ê·¸ë¦¬ê³ Â `cloud-controller-manager` (1.22)~~
            - `~~kubectl`Â (1.23/1.22)~~
        
    
    â€¢ `kubelet`ê³¼ í†µì‹ í•˜ëŠ”Â `kube-apiserver`Â ì¸ìŠ¤í„´ìŠ¤ëŠ”Â **1.23**Â ì´ì–´ì•¼ í•œë‹¤.
    
    í´ëŸ¬ìŠ¤í„° ì•ˆì˜Â `kubelet`Â ì¸ìŠ¤í„´ìŠ¤ë¥¼Â `kube-apiserver`ì˜ ë²„ì „ë³´ë‹¤ 2ë‹¨ê³„ ë‚®ì€ ë²„ì „ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•˜ì§€ ì•ŠëŠ”ë‹¤:
    
    **`kube-apiserver`ë¥¼ ì—…ê·¸ë ˆì´ë“œí•œë‹¤ë©´ í•œ ë‹¨ê³„ ë‚®ì€ ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•´ì•¼ í•œë‹¤.ì´ê²ƒì€ ê´€ë¦¬ë˜ê³  ìˆëŠ” 3ë‹¨ê³„ì˜ ë§ˆì´ë„ˆ ë²„ì „ë³´ë‹¤ ë‚®ì€Â `kubelet`ì„ ì‹¤í–‰í•  ê°€ëŠ¥ì„±ì„ ë†’ì¸ë‹¤.**
    

### (2) ì„¤ì¹˜

1. `apt` package ì—…ë°ì´íŠ¸ í›„, kubernetesÂ `apt` repositoryë¥¼ ì‚¬ìš©í•˜ëŠ” ë° í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜
    
    ```jsx
    root@master-node1:~# sudo apt-get update
    	Hit:1 https://download.docker.com/linux/ubuntu bionic InRelease
    	Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
    	Hit:3 http://kr.archive.ubuntu.com/ubuntu bionic InRelease
    	Get:4 http://kr.archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]
    	Get:5 http://kr.archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]
    	Fetched 252 kB in 3s (89.8 kB/s)
    	Reading package lists... Done
    root@master-node1:~# sudo apt-get install -y apt-transport-https ca-certificates curl
    	Reading package lists... Done
    	Building dependency tree
    	Reading state information... Done
    	ca-certificates is already the newest version (20210119~18.04.2).
    	curl is already the newest version (7.58.0-2ubuntu3.17).
    	The following NEW packages will be installed:
    	  apt-transport-https
    	0 upgraded, 1 newly installed, 0 to remove and 176 not upgraded.
    	Need to get 4,348 B of archives.
    	After this operation, 154 kB of additional disk space will be used.
    	Get:1 http://kr.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 apt-transport-https all 1.6.14 [4,348 B]
    	Fetched 4,348 B in 1s (8,481 B/s)
    	Selecting previously unselected package apt-transport-https.
    	(Reading database ... 107127 files and directories currently installed.)
    	Preparing to unpack .../apt-transport-https_1.6.14_all.deb ...
    	Unpacking apt-transport-https (1.6.14) ...
    	Setting up apt-transport-https (1.6.14) ...
    ```
    
    
2. êµ¬ê¸€ í´ë¼ìš°ë“œì˜ public signing keyë¥¼ ë‹¤ìš´ë¡œë“œ í•œë‹¤.
    
    ```jsx
    root@master-node1:~# sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
    ```
    
    
3. KubernetesÂ `apt` repositoryë¥¼ ì¶”ê°€í•œë‹¤.
    
    ```jsx
    root@master-node1:~# echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
    deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main
    ```
    
    
4. `apt`Â package ì—…ë°ì´íŠ¸ í›„ kubelet, kubeadm, kubectlì„ ì„¤ì¹˜í•˜ê³  í•´ë‹¹ ë²„ì „ì„ ê³ ì •í•œë‹¤.
    
    ```jsx
    root@master-node1:~# sudo apt-get update
    	Hit:1 https://download.docker.com/linux/ubuntu bionic InRelease
    	Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease
    	Hit:4 http://kr.archive.ubuntu.com/ubuntu bionic InRelease
    	Hit:5 http://kr.archive.ubuntu.com/ubuntu bionic-updates InRelease
    	Get:2 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [9,383 B]
    	Ign:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages
    	Hit:7 http://kr.archive.ubuntu.com/ubuntu bionic-backports InRelease
    	Ign:6 https://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
    	Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [55.3 kB]
    	Fetched 64.7 kB in 3s (18.5 kB/s)
    	Reading package lists... Done
    root@master-node1:~# sudo apt-get install -y kubelet kubeadm kubectl
    root@master-node1:~# sudo apt-mark hold kubelet kubeadm kubectl
    	kubelet set on hold.
    	kubeadm set on hold.
    	kubectl set on hold.
    ```
    

## 4) Swap ë©”ëª¨ë¦¬ ë¹„í™œì„±í™”_<small>Master Node/Worker Node</small>

- kubeletì€ Swap ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•  ì‹œ **ì—ëŸ¬ê°€ ë°œìƒ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ Master/Worker Node ëª¨ë‘ Swap ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
- ì‚¬ìš© ì¤‘ì¸ Swap ë©”ëª¨ë¦¬ í™•ì¸ : `top -d 1` > Swap í•„í„° ì ìš© > í™•ì¸

```jsx
// í˜„ì¬ ìŠ¤ì™‘ë©”ëª¨ë¦¬ ë¹„í™œì„±í™”
root@worker-node1:~# swapoff -a
// ì˜êµ¬ì ìœ¼ë¡œ ë¹„í™œì„±í™”
root@worker-node1:~# sed -i '2s/^/#/' /etc/fstab
```


# 2. Master Node Settings

## 1) Control Components ì„¤ì¹˜

```jsx
root@master-node1:~# kubeadm config images pull
	[config/images] Pulled k8s.gcr.io/kube-apiserver:v1.23.6
	[config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.23.6
	[config/images] Pulled k8s.gcr.io/kube-scheduler:v1.23.6
	[config/images] Pulled k8s.gcr.io/kube-proxy:v1.23.6
	[config/images] Pulled k8s.gcr.io/pause:3.6
	[config/images] Pulled k8s.gcr.io/etcd:3.5.1-0
	[config/images] Pulled k8s.gcr.io/coredns/coredns:v1.8.6
```


## 2) Kubeadm Init

```jsx
root@master-node1:~# kubeadm init
	[init] Using Kubernetes version: v1.23.6
	[preflight] Running pre-flight checks
	[preflight] Pulling images required for setting up a Kubernetes cluster
	[preflight] This might take a minute or two, depending on the speed of your internet connection
	[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
	[certs] Using certificateDir folder "/etc/kubernetes/pki"
	[certs] Generating "ca" certificate and key
	[certs] Generating "apiserver" certificate and key
	[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernet   es.default.svc.cluster.local master-node1] and IPs [10.96.0.1 10.41.2.156]
	[certs] Generating "apiserver-kubelet-client" certificate and key
	[certs] Generating "front-proxy-ca" certificate and key
	[certs] Generating "front-proxy-client" certificate and key
	[certs] Generating "etcd/ca" certificate and key
	[certs] Generating "etcd/server" certificate and key
	[certs] etcd/server serving cert is signed for DNS names [localhost master-node1] and IPs [10.41.2.156 127.0.0.1 ::1]
	[certs] Generating "etcd/peer" certificate and key
	[certs] etcd/peer serving cert is signed for DNS names [localhost master-node1] and IPs [10.41.2.156 127.0.0.1 ::1]
	[certs] Generating "etcd/healthcheck-client" certificate and key
	[certs] Generating "apiserver-etcd-client" certificate and key
	[certs] Generating "sa" key and public key
	[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
	[kubeconfig] Writing "admin.conf" kubeconfig file
	[kubeconfig] Writing "kubelet.conf" kubeconfig file
	[kubeconfig] Writing "controller-manager.conf" kubeconfig file
	[kubeconfig] Writing "scheduler.conf" kubeconfig file
	[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
	[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
	[kubelet-start] Starting the kubelet
	[control-plane] Using manifest folder "/etc/kubernetes/manifests"
	[control-plane] Creating static Pod manifest for "kube-apiserver"
	[control-plane] Creating static Pod manifest for "kube-controller-manager"
	[control-plane] Creating static Pod manifest for "kube-scheduler"
	[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
	[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kuberne   tes/manifests". This can take up to 4m0s
	[apiclient] All control plane components are healthy after 7.503627 seconds
	[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
	[kubelet] Creating a ConfigMap "kubelet-config-1.23" in namespace kube-system with the configuration for the kubelets    in the cluster
	NOTE: The "kubelet-config-1.23" naming of the kubelet ConfigMap is deprecated. Once the UnversionedKubeletConfigMap f   eature gate graduates to Beta the default name will become just "kubelet-config". Kubeadm upgrade will handle this tr   ansition transparently.
	[upload-certs] Skipping phase. Please see --upload-certs
	[mark-control-plane] Marking the node master-node1 as control-plane by adding the labels: [node-role.kubernetes.io/ma   ster(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
	[mark-control-plane] Marking the node master-node1 as control-plane by adding the taints [node-role.kubernetes.io/mas   ter:NoSchedule]
	[bootstrap-token] Using token: 65z741.dd70q5p4d17ch3cv
	[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
	[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
	[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long te   rm certificate credentials
	[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bo   otstrap Token
	[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
	[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
	[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
	[addons] Applied essential addon: CoreDNS
	[addons] Applied essential addon: kube-proxy
	
	Your Kubernetes control-plane has initialized successfully!
	
	To start using your cluster, you need to run the following as a regular user:
	
	  mkdir -p $HOME/.kube
	  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
	  sudo chown $(id -u):$(id -g) $HOME/.kube/config
	
	Alternatively, if you are the root user, you can run:
	
	  export KUBECONFIG=/etc/kubernetes/admin.conf
	
	You should now deploy a pod network to the cluster.
	Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
	  https://kubernetes.io/docs/concepts/cluster-administration/addons/
	
	Then you can join any number of worker nodes by running the following on each as root:
	
	kubeadm join 10.41.2.156:6443 --token 65z741.dd70q5p4d17ch3cv \
	        --discovery-token-ca-cert-hash sha256:a6949071dd2204e2ae577f890f5c58b330b0055ee14773f702647895be919c0a
```



### ì‹œí–‰ì°©ì˜¤

### ì—ëŸ¬ ë¡œê·¸

```jsx
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get "http://localhost:10248/healthz": dial tcp 127.0.0.1:10248: connect: connection refused.

        Unfortunately, an error has occurred:
                timed out waiting for the condition

        This error is likely caused by:
                - The kubelet is not running
                - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)

        If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:
                - 'systemctl status kubelet'
                - 'journalctl -xeu kubelet'

        Additionally, a control plane component may have crashed or exited when started by the container runtime.
        To troubleshoot, list all containers using your preferred container runtimes CLI.

        Here is one example how you may list all Kubernetes containers running in docker:
                - 'docker ps -a | grep kube | grep -v pause'
                Once you have found the failing container, you can inspect its logs with:
                - 'docker logs CONTAINERID'

error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster
To see the stack trace of this error execute with --v=5 or higher
```


### ì›ì¸ ì¶”ì 

```jsx
root@master-node1:~# systemctl status kubelet
	â— kubelet.service - kubelet: The Kubernetes Node Agent
	   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enable
	  Drop-In: /etc/systemd/system/kubelet.service.d
	           â””â”€10-kubeadm.conf
	   Active: activating (auto-restart) (Result: exit-code) since Tue 2022-05-03 00:31:01
	     Docs: https://kubernetes.io/docs/home/
	  Process: 8735 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_AR
	 Main PID: 8735 (code=exited, status=1/FAILURE)
root@master-node1:~# docker ps -a | grep kube | grep -v pause
root@master-node1:~# docker logs CONTAINERID
	Error: No such container: CONTAINERID
```


### í•´ê²° ë°©ë²•

- Container Runtimeì¸ Dockerë¥¼ ì œëŒ€ë¡œ ì„¤ì¹˜ ì•ˆí•´ì¤˜ì„œ ë°œìƒí•œ ì—ëŸ¬
    - `daemon.json` íŒŒì¼ ìƒì„± â†’ `kubeadm reset` â†’ `kubeadm init`
    
    ```jsx
    root@master-node1:~# cat > /etc/docker/daemon.json <<EOF
    	> {
    	>   "exec-opts": ["native.cgroupdriver=systemd"],
    	>   "log-driver": "json-file",
    	>   "log-opts": {
    	>     "max-size": "100m"
    	>   },
    	>   "storage-driver": "overlay2"
    	> }
    	> EOF
    root@master-node1:~# mkdir -p /etc/systemd/system/docker.service.d
    root@master-node1:~# systemctl daemon-reload
    root@master-node1:~# systemctl restart docker
    root@master-node1:~# kubeadm reset
    	[reset] Reading configuration from the cluster...
    	[reset] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-confi                      g -o yaml'
    	W0503 00:56:43.361756   26579 reset.go:101] [reset] Unable to fetch the kubeadm-config ConfigMa                      p from cluster: failed to get config map: configmaps "kubeadm-config" not found
    	[reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted                      .
    	[reset] Are you sure you want to proceed? [y/N]: y
    	[preflight] Running pre-flight checks
    	W0503 00:57:41.933212   26579 removeetcdmember.go:80] [reset] No kubeadm config, using etcd pod spec to get data directory
    	[reset] Stopping the kubelet service
    	[reset] Unmounting mounted directories in "/var/lib/kubelet"
    	[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
    	[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
    	[reset] Deleting contents of stateful directories: [/var/lib/etcd /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni]
    
    	The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d
    	
    	The reset process does not reset or clean up iptables rules or IPVS tables.
    	If you wish to reset iptables, you must do so manually by using the "iptables" command.
    	
    	If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)
    	to reset your system's IPVS tables.
    	
    	The reset process does not clean your kubeconfig files and you must remove them manually.
    	Please, check the contents of the $HOME/.kube/config file.
    
    root@master-node1:~# kubeadm init
    ```
    

## 3) Kubectl ì„¤ì •

```jsx
root@master-node1:~# mkdir -p $HOME/.kube
root@master-node1:~# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
root@master-node1:~# sudo chown $(id -u):$(id -g) $HOME/.kube/config
```


# 3. ë„¤íŠ¸ì›Œí¬ í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜_<small>Master Node</small>

- pod ê°„ì˜ í†µì‹ ì„ ìœ„í•´ ì„¤ì¹˜ í•„ìš”
- ë„¤íŠ¸ì›Œí¬ í”ŒëŸ¬ê·¸ì¸ ì¢…ë¥˜
    - Weave  
        `kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"`
        
    - Flannel  
        `kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml`
        
    - Calico  
        `kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml`
        
- **Calico ì„¤ì¹˜**
    
    ```jsx
    root@master-node1:~# kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml**
    	configmap/calico-config created
    	....ì¤‘ëµ....
    	daemonset.apps/calico-node created
    	serviceaccount/calico-node created
    	deployment.apps/calico-kube-controllers created
    	serviceaccount/calico-kube-controllers created
    	Warning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget
    	poddisruptionbudget.policy/calico-kube-controllers created
    ```
    

# 4. Worker Node Settings

## 1) Kubeadm Join

```jsx
root@worker-node1:~# kubeadm join 10.41.2.156:6443 --token 0toaxd.7se6f4jxz6zlu1qr --discovery-token-ca-cert-hash sha256:a6949071dd2204e2ae577f890f5c58b330b0055ee14773f702647895be919c0a
	[preflight] Running pre-flight checks
	[preflight] Reading configuration from the cluster...
	[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
	W0503 01:50:32.857613   16706 utils.go:69] The recommended value for "resolvConf" in "KubeletConfiguration" is: /run/systemd/resolve/resolv.conf; the provided value is: /run/systemd/resolve/resolv.conf
	[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
	[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
	[kubelet-start] Starting the kubelet
	[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
	
	This node has joined the cluster:
	* Certificate signing request was sent to apiserver and a response was received.
	* The Kubelet was informed of the new secure connection details.
	
	Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
```


### ì‹œí–‰ì°©ì˜¤

### ì—ëŸ¬ ë¡œê·¸

```jsx
root@worker-node1:~# kubeadm join 10.41.2.156:6443 --token 65z741.dd70q5p4d17ch3cv \
>         --discovery-token-ca-cert-hash sha256:a6949071dd2204e2ae577f890f5c58b330b0055ee14773f70264789
	[preflight] Running pre-flight checks
	error execution phase preflight: couldn't validate the identity of the API Server: invalid discovery token CA certificate hash: invalid hash "sha256:a6949071dd2204e2ae577f890f5c58b330b0055ee14773f70264789", expected a 32 byte SHA-256 hash, found 27 bytes
	To see the stack trace of this error execute with --v=5 or higher
```


### ì›ì¸ ë° í•´ê²°ë°©ë²•

- í† í°ì´ ë§ì§€ ì•Šì•„ì„œ ìƒê¸´ ì—ëŸ¬
- í† í° ì¬ìƒì„±

```jsx
root@master-node1:~# kubeadm token list
	TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS
	65z741.dd70q5p4d17ch3cv   23h         2022-05-03T15:59:09Z   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token
root@master-node1:~# kubeadm token delete 65z741.dd70q5p4d17ch3cv
	bootstrap token "65z741" deleted
root@master-node1:~# kubeadm token list
root@master-node1:~# kubeadm token create --print-join-command
	kubeadm join 10.41.2.156:6443 --token 0toaxd.7se6f4jxz6zlu1qr --discovery-token-ca-cert-hash sha256:a6949071dd2204e2ae577f890f5c58b330b0055ee14773f702647895be919c0a
```


## 2) ê° ë…¸ë“œ ìƒíƒœ í™•ì¸

### (1) Kubectl get nodes

```jsx
root@master-node1:~# kubectl get node
	NAME           STATUS   ROLES                  AGE     VERSION
	master-node1   Ready    control-plane,master   56m     v1.23.6
	worker-node1   Ready    <none>                 5m30s   v1.23.6
```


### (2) Kubectl get cs

```jsx
root@master-node1:~# kubectl get cs
	Warning: v1 ComponentStatus is deprecated in v1.19+
	NAME                 STATUS    MESSAGE                         ERROR
	scheduler            Healthy   ok
	controller-manager   Healthy   ok
	etcd-0               Healthy   {"health":"true","reason":""}
```


### (3) API êµ¬ì„± ìš”ì†Œ í™•ì¸

```jsx
root@master-node1:~# kubectl get po -o custom-columns=POD:metadata.name,NODE:spec.nodeNam  e --sort-by spec.nodeName -n kube-system
POD                                       NODE
calico-kube-controllers-7c845d499-crnbg   master-node1
kube-controller-manager-master-node1      master-node1
calico-node-svp7t                         master-node1
coredns-64897985d-b6g7z                   master-node1
coredns-64897985d-w2rcv                   master-node1
etcd-master-node1                         master-node1
kube-apiserver-master-node1               master-node1
kube-proxy-86k76                          master-node1
kube-scheduler-master-node1               master-node1
calico-node-j8d59                         worker-node1
kube-proxy-j257x                          worker-node1
```


# ì°¸ê³ 

- Docker ê³µì‹ ë¬¸ì„œ
	- Docker storage driver : [https://docs.docker.com/storage/storagedriver/select-storage-driver/](https://docs.docker.com/storage/storagedriver/select-storage-driver/)
	- Install Docker Engine on Ubuntu : [https://docs.docker.com/engine/install/ubuntu/](https://docs.docker.com/engine/install/ubuntu/)
- Kubernetes ê³µì‹ ë¬¸ì„œ
	- ë²„ì „ ì°¨ì´(skew) ì •ì±… : [https://kubernetes.io/ko/releases/version-skew-policy/](https://kubernetes.io/ko/releases/version-skew-policy/)
	- Creating a cluster with kubeadm : [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#version-skew-policy](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#version-skew-policy)
- NCP ê°€ì´ë“œ
	- ë¦¬ëˆ…ìŠ¤ ì„œë²„ ìƒì„± : [https://www.ncloud.com/guideCenter/guide/1](https://www.ncloud.com/guideCenter/guide/1)
